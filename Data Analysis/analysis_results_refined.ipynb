{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS Data Analysis - Structural Schema & Relationship Mapping\n",
    "\n",
    "This notebook focuses on identifying the database schema, Primary Keys (PK), and Foreign Keys (FK) to determine table relationships and isolate irrelevant (junk) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:25:04.415696Z",
     "iopub.status.busy": "2025-12-07T08:25:04.414985Z",
     "iopub.status.idle": "2025-12-07T08:25:05.292635Z",
     "shell.execute_reply": "2025-12-07T08:25:05.291468Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Clean Data\n",
    "Loading all CSVs and dropping the `index` column immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:25:05.292635Z",
     "iopub.status.busy": "2025-12-07T08:25:05.292635Z",
     "iopub.status.idle": "2025-12-07T08:25:06.247310Z",
     "shell.execute_reply": "2025-12-07T08:25:06.246288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\AppData\\Local\\Temp\\ipykernel_11836\\773723843.py:9: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, encoding='utf-8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Amazon Sale Report.csv: (128975, 23)\n",
      "Loaded Cloud Warehouse Compersion Chart.csv: (50, 3)\n",
      "Loaded Expense IIGF.csv: (17, 4)\n",
      "Loaded International sale Report.csv: (37432, 9)\n",
      "Loaded May-2022.csv: (1330, 16)\n",
      "Loaded P  L March 2021.csv: (1330, 17)\n",
      "Loaded Sale Report.csv: (9271, 6)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'Sales Dataset'\n",
    "csv_files = glob.glob(os.path.join(DATA_PATH, \"*.csv\"))\n",
    "dataframes = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    filename = os.path.basename(file)\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='ISO-8859-1')\n",
    "            \n",
    "        # Drop 'index' column if it exists\n",
    "        if 'index' in df.columns:\n",
    "            df = df.drop(columns=['index'])\n",
    "            \n",
    "        # Standardize column names (strip whitespace, lower case for comparison)\n",
    "        # But keep original for display\n",
    "        df.columns = [c.strip() for c in df.columns]\n",
    "            \n",
    "        dataframes[filename] = df\n",
    "        print(f\"Loaded {filename}: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identify Primary Keys (PK)\n",
    "A Primary Key must be unique and non-null. We will check each column in every dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:25:06.250298Z",
     "iopub.status.busy": "2025-12-07T08:25:06.249308Z",
     "iopub.status.idle": "2025-12-07T08:25:06.395476Z",
     "shell.execute_reply": "2025-12-07T08:25:06.395476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Potential Primary Keys ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Sale Report.csv: []\n",
      "Cloud Warehouse Compersion Chart.csv: []\n",
      "Expense IIGF.csv: ['Unnamed: 3']\n",
      "International sale Report.csv: []\n",
      "May-2022.csv: ['Sku']\n",
      "P  L March 2021.csv: ['Sku']\n",
      "Sale Report.csv: []\n"
     ]
    }
   ],
   "source": [
    "potential_pks = {}\n",
    "\n",
    "print(\"--- Potential Primary Keys ---\")\n",
    "for name, df in dataframes.items():\n",
    "    pks = []\n",
    "    for col in df.columns:\n",
    "        if df[col].is_unique and not df[col].isnull().any():\n",
    "            pks.append(col)\n",
    "    potential_pks[name] = pks\n",
    "    print(f\"{name}: {pks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Relationships (Foreign Keys)\n",
    "We look for columns that share names and data content between tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:25:06.395476Z",
     "iopub.status.busy": "2025-12-07T08:25:06.395476Z",
     "iopub.status.idle": "2025-12-07T08:25:06.569589Z",
     "shell.execute_reply": "2025-12-07T08:25:06.568815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Relationship Mapping (Shared Columns) ---\n",
      "Amazon Sale Report.csv (Size) <-> International sale Report.csv (Size) | Overlap: 10\n",
      "Amazon Sale Report.csv (SKU) <-> International sale Report.csv (SKU) | Overlap: 3699\n",
      "Amazon Sale Report.csv (Style) <-> International sale Report.csv (Style) | Overlap: 977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Sale Report.csv (Date) <-> International sale Report.csv (DATE) | Overlap: 25\n",
      "Amazon Sale Report.csv (SKU) <-> May-2022.csv (Sku) | No content overlap (False Positive)\n",
      "Amazon Sale Report.csv (Category) <-> May-2022.csv (Category) | No content overlap (False Positive)\n",
      "Amazon Sale Report.csv (SKU) <-> P  L March 2021.csv (Sku) | No content overlap (False Positive)\n",
      "Amazon Sale Report.csv (Category) <-> P  L March 2021.csv (Category) | No content overlap (False Positive)\n",
      "Amazon Sale Report.csv (Category) <-> Sale Report.csv (Category) | No content overlap (False Positive)\n",
      "Amazon Sale Report.csv (Size) <-> Sale Report.csv (Size) | Overlap: 9\n",
      "Cloud Warehouse Compersion Chart.csv (Unnamed: 1) <-> Expense IIGF.csv (Unnamed: 1) | No content overlap (False Positive)\n",
      "International sale Report.csv (SKU) <-> May-2022.csv (Sku) | No content overlap (False Positive)\n",
      "International sale Report.csv (SKU) <-> P  L March 2021.csv (Sku) | No content overlap (False Positive)\n",
      "International sale Report.csv (Size) <-> Sale Report.csv (Size) | Overlap: 11\n",
      "May-2022.csv (Snapdeal MRP) <-> P  L March 2021.csv (Snapdeal MRP) | Overlap: 52\n",
      "May-2022.csv (Style Id) <-> P  L March 2021.csv (Style Id) | Overlap: 252\n",
      "May-2022.csv (Amazon FBA MRP) <-> P  L March 2021.csv (Amazon FBA MRP) | Overlap: 53\n",
      "May-2022.csv (Flipkart MRP) <-> P  L March 2021.csv (Flipkart MRP) | Overlap: 52\n",
      "May-2022.csv (MRP Old) <-> P  L March 2021.csv (MRP Old) | Overlap: 67\n",
      "May-2022.csv (Ajio MRP) <-> P  L March 2021.csv (Ajio MRP) | Overlap: 52\n",
      "May-2022.csv (Category) <-> P  L March 2021.csv (Category) | Overlap: 5\n",
      "May-2022.csv (Sku) <-> P  L March 2021.csv (Sku) | Overlap: 1330\n",
      "May-2022.csv (Limeroad MRP) <-> P  L March 2021.csv (Limeroad MRP) | Overlap: 52\n",
      "May-2022.csv (Catalog) <-> P  L March 2021.csv (Catalog) | Overlap: 9\n",
      "May-2022.csv (Myntra MRP) <-> P  L March 2021.csv (Myntra MRP) | Overlap: 51\n",
      "May-2022.csv (Amazon MRP) <-> P  L March 2021.csv (Amazon MRP) | Overlap: 53\n",
      "May-2022.csv (Weight) <-> P  L March 2021.csv (Weight) | Overlap: 4\n",
      "May-2022.csv (Final MRP Old) <-> P  L March 2021.csv (Final MRP Old) | Overlap: 53\n",
      "May-2022.csv (Paytm MRP) <-> P  L March 2021.csv (Paytm MRP) | Overlap: 52\n",
      "May-2022.csv (Category) <-> Sale Report.csv (Category) | No content overlap (False Positive)\n",
      "P  L March 2021.csv (Category) <-> Sale Report.csv (Category) | No content overlap (False Positive)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Relationship Mapping (Shared Columns) ---\")\n",
    "file_pairs = itertools.combinations(dataframes.keys(), 2)\n",
    "connections = []\n",
    "\n",
    "for name1, name2 in file_pairs:\n",
    "    cols1 = set(dataframes[name1].columns)\n",
    "    cols2 = set(dataframes[name2].columns)\n",
    "    \n",
    "    # Find common columns\n",
    "    common_cols = cols1.intersection(cols2)\n",
    "    \n",
    "    # Also check for fuzzy matches (e.g. 'SKU' vs 'Sku' vs 'SKU Code')\n",
    "    # We'll normalize to lower case for this check\n",
    "    cols1_lower = {c.lower(): c for c in cols1}\n",
    "    cols2_lower = {c.lower(): c for c in cols2}\n",
    "    common_lower = set(cols1_lower.keys()).intersection(set(cols2_lower.keys()))\n",
    "    \n",
    "    for c_lower in common_lower:\n",
    "        c1 = cols1_lower[c_lower]\n",
    "        c2 = cols2_lower[c_lower]\n",
    "        \n",
    "        # Verify content overlap to confirm it's a real relationship\n",
    "        vals1 = set(dataframes[name1][c1].dropna().unique())\n",
    "        vals2 = set(dataframes[name2][c2].dropna().unique())\n",
    "        \n",
    "        overlap = vals1.intersection(vals2)\n",
    "        if len(overlap) > 0:\n",
    "            print(f\"{name1} ({c1}) <-> {name2} ({c2}) | Overlap: {len(overlap)}\")\n",
    "            connections.append((name1, name2))\n",
    "        else:\n",
    "             print(f\"{name1} ({c1}) <-> {name2} ({c2}) | No content overlap (False Positive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Isolate Junk Tables\n",
    "Tables that have NO connections to others are likely junk or standalone reference files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T08:25:06.573158Z",
     "iopub.status.busy": "2025-12-07T08:25:06.573158Z",
     "iopub.status.idle": "2025-12-07T08:25:06.593581Z",
     "shell.execute_reply": "2025-12-07T08:25:06.593581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Connected Files (Core Schema) ---\n",
      "P  L March 2021.csv\n",
      "Sale Report.csv\n",
      "International sale Report.csv\n",
      "May-2022.csv\n",
      "Amazon Sale Report.csv\n",
      "\n",
      "--- Isolated Files (Potential Junk) ---\n",
      "Expense IIGF.csv\n",
      "Preview of Expense IIGF.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recived Amount</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Expance</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Particular</td>\n",
       "      <td>Amount</td>\n",
       "      <td>Particular</td>\n",
       "      <td>Amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06-19-22</td>\n",
       "      <td>1000</td>\n",
       "      <td>Large Bag</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-20-22</td>\n",
       "      <td>1500</td>\n",
       "      <td>Stationary(Soft Pin, Paper pin for Dupatta, Fe...</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06-22-22</td>\n",
       "      <td>500</td>\n",
       "      <td>OLA</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06-23-22</td>\n",
       "      <td>2000</td>\n",
       "      <td>Auto Rent</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Recived Amount Unnamed: 1  \\\n",
       "0     Particular     Amount   \n",
       "1       06-19-22       1000   \n",
       "2       06-20-22       1500   \n",
       "3       06-22-22        500   \n",
       "4       06-23-22       2000   \n",
       "\n",
       "                                             Expance Unnamed: 3  \n",
       "0                                         Particular     Amount  \n",
       "1                                          Large Bag        380  \n",
       "2  Stationary(Soft Pin, Paper pin for Dupatta, Fe...        170  \n",
       "3                                                OLA        839  \n",
       "4                                          Auto Rent        520  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Warehouse Compersion Chart.csv\n",
      "Preview of Cloud Warehouse Compersion Chart.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shiprocket</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>INCREFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Heads</td>\n",
       "      <td>Price (Per Unit)</td>\n",
       "      <td>Price (Per Unit)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inbound (Fresh Stock and RTO)</td>\n",
       "      <td>₹4.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outbound</td>\n",
       "      <td>₹7.00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Storage Fee/Cft</td>\n",
       "      <td>₹25.00</td>\n",
       "      <td>Rs 0.15/- Per Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Return with Detailed QC</td>\n",
       "      <td>₹6.00</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Shiprocket        Unnamed: 1            INCREFF\n",
       "0                             Heads  Price (Per Unit)   Price (Per Unit)\n",
       "1     Inbound (Fresh Stock and RTO)             ₹4.00                  4\n",
       "2                          Outbound             ₹7.00                 11\n",
       "3                   Storage Fee/Cft            ₹25.00  Rs 0.15/- Per Day\n",
       "4  Customer Return with Detailed QC             ₹6.00               15.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connected_files = set()\n",
    "for n1, n2 in connections:\n",
    "    connected_files.add(n1)\n",
    "    connected_files.add(n2)\n",
    "    \n",
    "all_files = set(dataframes.keys())\n",
    "junk_files = all_files - connected_files\n",
    "\n",
    "print(\"\\n--- Connected Files (Core Schema) ---\")\n",
    "for f in connected_files:\n",
    "    print(f)\n",
    "\n",
    "print(\"\\n--- Isolated Files (Potential Junk) ---\")\n",
    "for f in junk_files:\n",
    "    print(f)\n",
    "    print(f\"Preview of {f}:\")\n",
    "    display(dataframes[f].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
